{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(\"generated_caption_model.csv\")\n",
        "\n",
        "models = {\n",
        "    \"Model M1\": \"M1_caption\",\n",
        "    \"Model M2\": \"M2_caption\",\n",
        "    \"Model M3\": \"M3_caption\"\n",
        "}\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "eda_results = {}\n",
        "\n",
        "# ---------- Helper Functions ----------\n",
        "\n",
        "def vocabulary_richness(captions):\n",
        "    tokens = [w for cap in captions for w in word_tokenize(cap.lower())]\n",
        "    return len(set(tokens)) / len(tokens)\n",
        "\n",
        "def avg_caption_length(captions):\n",
        "    return np.mean([len(word_tokenize(c)) for c in captions])\n",
        "\n",
        "def sentiment_score(captions):\n",
        "    return np.mean([sia.polarity_scores(c)[\"compound\"] for c in captions])\n",
        "\n",
        "def pos_diversity(captions):\n",
        "    pos_tags = []\n",
        "    for c in captions:\n",
        "        pos_tags += [tag for _, tag in pos_tag(word_tokenize(c))]\n",
        "    return len(set(pos_tags)) / len(pos_tags)\n",
        "\n",
        "def semantic_similarity(refs, cands):\n",
        "    ref_emb = embedder.encode(refs, convert_to_tensor=True)\n",
        "    cand_emb = embedder.encode(cands, convert_to_tensor=True)\n",
        "    return util.cos_sim(ref_emb, cand_emb).mean().item()\n",
        "\n",
        "# ---------- Compute EDA ----------\n",
        "\n",
        "for model, col in models.items():\n",
        "    captions = df[col].astype(str).tolist()\n",
        "    references = df[\"reference_caption\"].astype(str).tolist()\n",
        "\n",
        "    eda_results[model] = {\n",
        "        \"Vocabulary\": vocabulary_richness(captions),\n",
        "        \"Readability\": avg_caption_length(captions),\n",
        "        \"Sentiment\": sentiment_score(captions),\n",
        "        \"POS Diversity\": pos_diversity(captions),\n",
        "        \"Similarity\": semantic_similarity(references, captions)\n",
        "    }\n",
        "\n",
        "# ---------- Normalize (0–1 scale) ----------\n",
        "\n",
        "eda_df = pd.DataFrame(eda_results).T\n",
        "eda_df = (eda_df - eda_df.min()) / (eda_df.max() - eda_df.min())\n",
        "\n",
        "eda_df.reset_index(inplace=True)\n",
        "eda_df.rename(columns={\"index\": \"Model\"}, inplace=True)\n",
        "\n",
        "eda_df.to_csv(\"eda_results_real.csv\", index=False)\n",
        "\n",
        "print(\"✅ REAL EDA computed and saved to eda_results_real.csv\")\n",
        "print(eda_df)\n"
      ],
      "metadata": {
        "id": "B9X3wHZ3LjYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}